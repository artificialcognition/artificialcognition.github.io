<!DOCTYPE html>
<html lang="en">

	<head>
		<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1" />


	<title>Project: Using a Deep-Belief Neural Network to Diagnose Breast Cancer</title>


<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@" />
<meta name="twitter:title" content="Project: Using a Deep-Belief Neural Network to Diagnose Breast Cancer" />
<meta name="twitter:description" content="I started learning more about deep-belief networks because of all the latest news surrounding this tool. Basically, they are Restricted Boltzmann Machines stacked together and have been shown to be...">

<meta name="description" content="I started learning more about deep-belief networks because of all the latest news surrounding this tool. Basically, they are Restricted Boltzmann Machines st...">



<link rel="icon" href="/assets/favicon.png">
<link rel="apple-touch-icon" href="/assets/touch-icon.png">
<link href="https://fonts.googleapis.com/css?family=Karla" rel="stylesheet">
<link rel="stylesheet" href="/assets/core.css">
<link rel="canonical" href="/using-a-deep-belief-neural-network-to-diagnose-breast-cancer">
<link rel="alternate" type="application/atom+xml" title="Artificial Cognition" href="/feed.xml" />



   
	</head>

	<body>

		<aside class="logo">

	

	<a href="/">
		<img src="/../walle.png" class="gravatar">
	</a>
	<span class="logo-prompt">Back to Home</span>

</aside>


		<main>
			<article>

	<div class="center">
		<h1>Project: Using a Deep-Belief Neural Network to Diagnose Breast Cancer</h1>
	</div>

	<div class="divider"></div>

	<p>I started learning more about deep-belief networks because of all the latest news surrounding this tool. Basically, they are Restricted Boltzmann Machines stacked together and have been shown to be extremely useful in classifying things.</p>

<p>I followed a <a href="http://www.pyimagesearch.com/2014/09/22/getting-started-deep-learning-python/">tutorial</a> and had to learn a few libraries required for the DBN. And then, I decided to apply this to classify the <a href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)">Wisconsin Breast Cancer (Diagnostic) Data Set</a> to see if it would work on a real life (and extremely important) problem.</p>

<p>One shortcut I used to scale the data was as follows:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">b</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">d</span><span class="p">:</span>
        <span class="n">b</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c"># found using max point</span>
<span class="n">scaled</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">b</span><span class="p">)</span></code></pre></figure>

<p>Anyway, the results were promising with an accuracy of 94% overall in diagnosing breast cancer with a malignant diagnosis of 97%. This is very good because it means that it’s more likely than not to diagnose a false positive than a false negative.</p>

<p>Here’s the code:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">nolearn.dbn</span> <span class="kn">import</span> <span class="n">DBN</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_breast_cancer</span><span class="p">()</span>

<span class="n">b</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">d</span><span class="p">:</span>
        <span class="n">b</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c"># found using max point</span>
<span class="n">scaled</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

<span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">trainY</span><span class="p">,</span> <span class="n">testY</span><span class="p">)</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">scaled</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.33</span><span class="p">)</span>

<span class="n">dbn</span> <span class="o">=</span> <span class="n">DBN</span><span class="p">(</span>
	<span class="p">[</span><span class="n">trainX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
	<span class="n">learn_rates</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
	<span class="n">learn_rate_decays</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
	<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
	<span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">dbn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span><span class="p">)</span>

<span class="n">preds</span> <span class="o">=</span> <span class="n">dbn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testX</span><span class="p">)</span>

<span class="k">print</span> <span class="n">dataset</span><span class="o">.</span><span class="n">DESCR</span>

<span class="k">print</span> <span class="s">"0: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span> <span class="s">"1: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="k">print</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">testY</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span></code></pre></figure>

<p>This produces:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>[DBN] fitting X.shape=(381, 30)
[DBN] layers [30, 500, 500, 2]
[DBN] Fine-tune...
100%
Epoch 1:
  loss 0.667588567734
  err  0.41875
  (0:00:00)
100%
Epoch 2:
  loss 0.61961773634
  err  0.353125
  (0:00:00)
100%
Epoch 3:
  loss 0.544265073538
  err  0.215625
  (0:00:00)
100%
Epoch 4:
  loss 0.410316121578
  err  0.16875
  (0:00:00)
100%
Epoch 5:
  loss 0.314362972975
  err  0.10625
  (0:00:00)
100%
Epoch 6:
  loss 0.306012681127
  err  0.13125
  (0:00:00)
100%
Epoch 7:
  loss 0.242035767436
  err  0.11875
  (0:00:00)
100%
Epoch 8:
  loss 0.286982005835
  err  0.14375
  (0:00:00)
100%
Epoch 9:
  loss 0.22955622673
  err  0.121875
  (0:00:00)
100%
Epoch 10:
  loss 0.247347301245
  err  0.09375
  (0:00:00)
Breast Cancer Wisconsin (Diagnostic) Database

Notes
-----
Data Set Characteristics:
    :Number of Instances: 569

    :Number of Attributes: 30 numeric, predictive attributes and the class

    :Attribute Information:
        - radius (mean of distances from center to points on the perimeter)
        - texture (standard deviation of gray-scale values)
        - perimeter
        - area
        - smoothness (local variation in radius lengths)
        - compactness (perimeter^2 / area - 1.0)
        - concavity (severity of concave portions of the contour)
        - concave points (number of concave portions of the contour)
        - symmetry
        - fractal dimension ("coastline approximation" - 1)

        The mean, standard error, and "worst" or largest (mean of the three
        largest values) of these features were computed for each image,
        resulting in 30 features.  For instance, field 3 is Mean Radius, field
        13 is Radius SE, field 23 is Worst Radius.

        - class:
                - WDBC-Malignant
                - WDBC-Benign

    :Summary Statistics:

    ===================================== ======= ========
                                           Min     Max
    ===================================== ======= ========
    radius (mean):                         6.981   28.11
    texture (mean):                        9.71    39.28
    perimeter (mean):                      43.79   188.5
    area (mean):                           143.5   2501.0
    smoothness (mean):                     0.053   0.163
    compactness (mean):                    0.019   0.345
    concavity (mean):                      0.0     0.427
    concave points (mean):                 0.0     0.201
    symmetry (mean):                       0.106   0.304
    fractal dimension (mean):              0.05    0.097
    radius (standard error):               0.112   2.873
    texture (standard error):              0.36    4.885
    perimeter (standard error):            0.757   21.98
    area (standard error):                 6.802   542.2
    smoothness (standard error):           0.002   0.031
    compactness (standard error):          0.002   0.135
    concavity (standard error):            0.0     0.396
    concave points (standard error):       0.0     0.053
    symmetry (standard error):             0.008   0.079
    fractal dimension (standard error):    0.001   0.03
    radius (worst):                        7.93    36.04
    texture (worst):                       12.02   49.54
    perimeter (worst):                     50.41   251.2
    area (worst):                          185.2   4254.0
    smoothness (worst):                    0.071   0.223
    compactness (worst):                   0.027   1.058
    concavity (worst):                     0.0     1.252
    concave points (worst):                0.0     0.291
    symmetry (worst):                      0.156   0.664
    fractal dimension (worst):             0.055   0.208
    ===================================== ======= ========

    :Missing Attribute Values: None

    :Class Distribution: 212 - Malignant, 357 - Benign

    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian

    :Donor: Nick Street

    :Date: November, 1995

This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.
https://goo.gl/U2Uwz2

Features are computed from a digitized image of a fine needle
aspirate (FNA) of a breast mass.  They describe
characteristics of the cell nuclei present in the image.
A few of the images can be found at
http://www.cs.wisc.edu/~street/images/

Separating plane described above was obtained using
Multisurface Method-Tree (MSM-T) [K. P. Bennett, "Decision Tree
Construction Via Linear Programming." Proceedings of the 4th
Midwest Artificial Intelligence and Cognitive Science Society,
pp. 97-101, 1992], a classification method which uses linear
programming to construct a decision tree.  Relevant features
were selected using an exhaustive search in the space of 1-4
features and 1-3 separating planes.

The actual linear program used to obtain the separating plane
in the 3-dimensional space is that described in:
[K. P. Bennett and O. L. Mangasarian: "Robust Linear
Programming Discrimination of Two Linearly Inseparable Sets",
Optimization Methods and Software 1, 1992, 23-34].

This database is also available through the UW CS ftp server:

ftp ftp.cs.wisc.edu
cd math-prog/cpo-dataset/machine-learn/WDBC/

References
----------
   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction
     for breast tumor diagnosis. IS&amp;T/SPIE 1993 International Symposium on
     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,
     San Jose, CA, 1993.
   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and
     prognosis via linear programming. Operations Research, 43(4), pages 570-577,
     July-August 1995.
   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques
     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)
     163-171.

0: malignant
1: benign
             precision    recall  f1-score   support

          0       0.97      0.85      0.90        66
          1       0.92      0.98      0.95       122

avg / total       0.94      0.94      0.94       188
</code></pre>
</div>



</article>

<div class="page-navigation">
	
    <a class="next" href="/who-owns-the-zebra" title="NEXT: Project: Solving Einstein's Puzzle with Python-Constraint">&lt;&lt;</a>
		<span> &middot; </span>
  
		<a class="home" href="/" title="Back to Homepage">Home</a>
  
		<span> &middot; </span>
    <a class="prev" href="/geometric-genetic-art-part-2" title="PREV: Project: Creating Visual Art with Genetic Algorithms Part 2">&gt;&gt;</a>
  
</div>

		</main>

		<div class="footer">
  <span class="block">Made with &hearts; using <a href="http://jekyllrb.com/">Jekyll</a> &amp; <a href="https://github.com/heiswayi/the-plain" title="The Plain theme by Heiswayi Nrird">The Plain</a> </span>
  <span class="block">&copy; 2017 </span>
</div>


	</body>

</html>
